Here is the code for our experiments on Shapnet Car Dataset:

This dataset contains the modeling of 2D orientation change as two individual orientation vectors.

1. To run our code, please first download our dataset. 
We put our dataset on the google drive: https://drive.google.com/file/d/1jxBLTMhxN0Wx-TBilkfrRq2JBstLw3jW/view?usp=sharing
Please download this dataset, and extract the dataset under the dataset directory.
After extraction, you should get the "dataset" directory contains a directory called "car" and the "car" 
directory contains 3 driectories ("cars_train" "cars_train_test" "cars_train_val"). This data is originally generated by
 the work of https://arxiv.org/abs/1906.01618. We record our split of the data as .txt file in each instance directory 
 (e.g. 'data_pair2_clean.txt' under each instance directory in the "cars_train" folder records the images we use to train
 our model for this instance). The dataloader provided in our code will automatically read in this files and load in data accordingly.
 

2. For novel view synthesis experiment, get into the "code" directory and run "novel_view_synthesis.py"

* For training the model, use the command: python novel_view_synthesis.py --train True
* After training, test the reconstruction and test the robustness to noise: python novel_view_synthesis.py
(We provide the checkpoint we get under the folder checkpoint)

For our experiment, we run the code at a single Titan RTX GPU(with 24GB memory) for 1 days. 

3. For camera pose estimation experiment, get into the "code" directory and run "inference.py"
Note that you need to first run the training to get the pose representation, then you can run this code.     
* For training the model, use the command: python inference.py --train True
* For testing: python inference.py
(We profvide the checkpoint we get under the folder, checkpoint_infer)